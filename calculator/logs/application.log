2025-01-06 23:31:04 - Registered kafka:type=kafka.Log4jController MBean
2025-01-06 23:31:04 - 
2025-01-06 23:31:04 -   ______                  _                                          
2025-01-06 23:31:04 -  |___  /                 | |                                         
2025-01-06 23:31:04 -     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __   
2025-01-06 23:31:04 -    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__|
2025-01-06 23:31:04 -   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |    
2025-01-06 23:31:04 -  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_|
2025-01-06 23:31:04 -                                               | |                     
2025-01-06 23:31:04 -                                               |_|                     
2025-01-06 23:31:04 - 
2025-01-06 23:31:04 - Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC
2025-01-06 23:31:04 - Server environment:host.name=HugoAbreu.home
2025-01-06 23:31:04 - Server environment:java.version=23.0.1
2025-01-06 23:31:04 - Server environment:java.vendor=Oracle Corporation
2025-01-06 23:31:04 - Server environment:java.home=C:\Oracle_JDK-23
2025-01-06 23:31:04 - Server environment:java.class.path=C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator\target\test-classes;C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator\target\classes;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter\3.4.1\spring-boot-starter-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot\3.4.1\spring-boot-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.4.1\spring-boot-autoconfigure-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.4.1\spring-boot-starter-logging-3.4.1.jar;C:\Users\hugom\.m2\repository\ch\qos\logback\logback-classic\1.5.12\logback-classic-1.5.12.jar;C:\Users\hugom\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.24.3\log4j-to-slf4j-2.24.3.jar;C:\Users\hugom\.m2\repository\org\apache\logging\log4j\log4j-api\2.24.3\log4j-api-2.24.3.jar;C:\Users\hugom\.m2\repository\org\slf4j\jul-to-slf4j\2.0.16\jul-to-slf4j-2.0.16.jar;C:\Users\hugom\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-core\6.2.1\spring-core-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-jcl\6.2.1\spring-jcl-6.2.1.jar;C:\Users\hugom\.m2\repository\org\yaml\snakeyaml\2.3\snakeyaml-2.3.jar;C:\Users\hugom\.m2\repository\org\springframework\kafka\spring-kafka\3.3.1\spring-kafka-3.3.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-context\6.2.1\spring-context-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-aop\6.2.1\spring-aop-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-beans\6.2.1\spring-beans-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-expression\6.2.1\spring-expression-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-messaging\6.2.1\spring-messaging-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-tx\6.2.1\spring-tx-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\retry\spring-retry\2.0.11\spring-retry-2.0.11.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-clients\3.8.1\kafka-clients-3.8.1.jar;C:\Users\hugom\.m2\repository\com\github\luben\zstd-jni\1.5.6-4\zstd-jni-1.5.6-4.jar;C:\Users\hugom\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\hugom\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.5\snappy-java-1.1.10.5.jar;C:\Users\hugom\.m2\repository\io\micrometer\micrometer-observation\1.14.2\micrometer-observation-1.14.2.jar;C:\Users\hugom\.m2\repository\io\micrometer\micrometer-commons\1.14.2\micrometer-commons-1.14.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-web\3.4.1\spring-boot-starter-web-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.4.1\spring-boot-starter-json-3.4.1.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.18.2\jackson-datatype-jdk8-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.18.2\jackson-datatype-jsr310-2.18.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\3.4.1\spring-boot-starter-tomcat-3.4.1.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\10.1.34\tomcat-embed-core-10.1.34.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\10.1.34\tomcat-embed-el-10.1.34.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\10.1.34\tomcat-embed-websocket-10.1.34.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-web\6.2.1\spring-web-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-webmvc\6.2.1\spring-webmvc-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-docker-compose\3.4.1\spring-boot-docker-compose-3.4.1.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.18.2\jackson-databind-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.18.2\jackson-annotations-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.18.2\jackson-core-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.18.2\jackson-module-parameter-names-2.18.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.4.1\spring-boot-starter-test-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-test\3.4.1\spring-boot-test-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.4.1\spring-boot-test-autoconfigure-3.4.1.jar;C:\Users\hugom\.m2\repository\com\jayway\jsonpath\json-path\2.9.0\json-path-2.9.0.jar;C:\Users\hugom\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.2\jakarta.xml.bind-api-4.0.2.jar;C:\Users\hugom\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.3\jakarta.activation-api-2.1.3.jar;C:\Users\hugom\.m2\repository\net\minidev\json-smart\2.5.1\json-smart-2.5.1.jar;C:\Users\hugom\.m2\repository\net\minidev\accessors-smart\2.5.1\accessors-smart-2.5.1.jar;C:\Users\hugom\.m2\repository\org\ow2\asm\asm\9.6\asm-9.6.jar;C:\Users\hugom\.m2\repository\org\assertj\assertj-core\3.26.3\assertj-core-3.26.3.jar;C:\Users\hugom\.m2\repository\net\bytebuddy\byte-buddy\1.15.11\byte-buddy-1.15.11.jar;C:\Users\hugom\.m2\repository\org\awaitility\awaitility\4.2.2\awaitility-4.2.2.jar;C:\Users\hugom\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter\5.11.4\junit-jupiter-5.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.11.4\junit-jupiter-params-5.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.11.4\junit-jupiter-engine-5.11.4.jar;C:\Users\hugom\.m2\repository\org\mockito\mockito-core\5.14.2\mockito-core-5.14.2.jar;C:\Users\hugom\.m2\repository\net\bytebuddy\byte-buddy-agent\1.15.11\byte-buddy-agent-1.15.11.jar;C:\Users\hugom\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\hugom\.m2\repository\org\mockito\mockito-junit-jupiter\5.14.2\mockito-junit-jupiter-5.14.2.jar;C:\Users\hugom\.m2\repository\org\skyscreamer\jsonassert\1.5.3\jsonassert-1.5.3.jar;C:\Users\hugom\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-test\6.2.1\spring-test-6.2.1.jar;C:\Users\hugom\.m2\repository\org\xmlunit\xmlunit-core\2.10.0\xmlunit-core-2.10.0.jar;C:\Users\hugom\.m2\repository\org\springframework\kafka\spring-kafka-test\3.3.1\spring-kafka-test-3.3.1.jar;C:\Users\hugom\.m2\repository\org\apache\zookeeper\zookeeper\3.8.4\zookeeper-3.8.4.jar;C:\Users\hugom\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.8.4\zookeeper-jute-3.8.4.jar;C:\Users\hugom\.m2\repository\org\apache\yetus\audience-annotations\0.12.0\audience-annotations-0.12.0.jar;C:\Users\hugom\.m2\repository\io\netty\netty-handler\4.1.116.Final\netty-handler-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-common\4.1.116.Final\netty-common-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-resolver\4.1.116.Final\netty-resolver-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-buffer\4.1.116.Final\netty-buffer-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport\4.1.116.Final\netty-transport-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.116.Final\netty-transport-native-unix-common-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-codec\4.1.116.Final\netty-codec-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-native-epoll\4.1.116.Final\netty-transport-native-epoll-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.116.Final\netty-transport-classes-epoll-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\ch\qos\logback\logback-core\1.5.12\logback-core-1.5.12.jar;C:\Users\hugom\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-clients\3.8.1\kafka-clients-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server\3.8.1\kafka-server-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.8.1\kafka-group-coordinator-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-transaction-coordinator\3.8.1\kafka-transaction-coordinator-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-raft\3.8.1\kafka-raft-3.8.1.jar;C:\Users\hugom\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-metadata\3.8.1\kafka-metadata-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server-common\3.8.1\kafka-server-common-3.8.1.jar;C:\Users\hugom\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\hugom\.m2\repository\org\pcollections\pcollections\4.0.1\pcollections-4.0.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server-common\3.8.1\kafka-server-common-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.8.1\kafka-streams-test-utils-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-streams\3.8.1\kafka-streams-3.8.1.jar;C:\Users\hugom\.m2\repository\org\rocksdb\rocksdbjni\7.9.2\rocksdbjni-7.9.2.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka_2.13\3.8.1\kafka_2.13-3.8.1.jar;C:\Users\hugom\.m2\repository\org\scala-lang\scala-library\2.13.14\scala-library-2.13.14.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-group-coordinator-api\3.8.1\kafka-group-coordinator-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-storage-api\3.8.1\kafka-storage-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-tools-api\3.8.1\kafka-tools-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-storage\3.8.1\kafka-storage-3.8.1.jar;C:\Users\hugom\.m2\repository\com\github\ben-manes\caffeine\caffeine\3.1.8\caffeine-3.1.8.jar;C:\Users\hugom\.m2\repository\org\checkerframework\checker-qual\3.37.0\checker-qual-3.37.0.jar;C:\Users\hugom\.m2\repository\com\google\errorprone\error_prone_annotations\2.21.1\error_prone_annotations-2.21.1.jar;C:\Users\hugom\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\hugom\.m2\repository\commons-validator\commons-validator\1.7\commons-validator-1.7.jar;C:\Users\hugom\.m2\repository\commons-beanutils\commons-beanutils\1.9.4\commons-beanutils-1.9.4.jar;C:\Users\hugom\.m2\repository\commons-digester\commons-digester\2.1\commons-digester-2.1.jar;C:\Users\hugom\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.18.2\jackson-module-scala_2.13-2.18.2.jar;C:\Users\hugom\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.18.2\jackson-dataformat-csv-2.18.2.jar;C:\Users\hugom\.m2\repository\org\bitbucket\b_c\jose4j\0.9.4\jose4j-0.9.4.jar;C:\Users\hugom\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\hugom\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\hugom\.m2\repository\org\scala-lang\scala-reflect\2.13.14\scala-reflect-2.13.14.jar;C:\Users\hugom\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\hugom\.m2\repository\io\dropwizard\metrics\metrics-core\4.1.12.1\metrics-core-4.1.12.1.jar;C:\Users\hugom\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka_2.13\3.8.1\kafka_2.13-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.11.4\junit-jupiter-api-5.11.4.jar;C:\Users\hugom\.m2\repository\org\opentest4j\opentest4j\1.3.0\opentest4j-1.3.0.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-commons\1.11.4\junit-platform-commons-1.11.4.jar;C:\Users\hugom\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-launcher\1.11.4\junit-platform-launcher-1.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-engine\1.11.4\junit-platform-engine-1.11.4.jar;C:\Users\hugom\.m2\repository\org\slf4j\slf4j-api\2.0.16\slf4j-api-2.0.16.jar;
2025-01-06 23:31:04 - Server environment:java.library.path=C:\Oracle_JDK-23\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\nodejs\;C:\Program Files\Git\cmd;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Program Files\Docker\Docker\resources\bin;C:\Users\hugom\Downloads\apache-maven-3.9.9\bin;C:\Users\hugom\AppData\Local\Microsoft\WindowsApps;C:\Users\hugom\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\hugom\AppData\Roaming\npm;C:\Program Files\Git\cmd;C:\Users\hugom\AppData\Local\Android\Sdk\platform-tools;C:\Program Files\sf\bin;;.
2025-01-06 23:31:04 - Server environment:java.io.tmpdir=C:\Users\hugom\AppData\Local\Temp\
2025-01-06 23:31:04 - Server environment:java.compiler=<NA>
2025-01-06 23:31:04 - Server environment:os.name=Windows 11
2025-01-06 23:31:04 - Server environment:os.arch=amd64
2025-01-06 23:31:04 - Server environment:os.version=10.0
2025-01-06 23:31:04 - Server environment:user.name=hugom
2025-01-06 23:31:04 - Server environment:user.home=C:\Users\hugom
2025-01-06 23:31:04 - Server environment:user.dir=C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator
2025-01-06 23:31:04 - Server environment:os.memory.free=71MB
2025-01-06 23:31:04 - Server environment:os.memory.max=3934MB
2025-01-06 23:31:04 - Server environment:os.memory.total=88MB
2025-01-06 23:31:04 - zookeeper.enableEagerACLCheck = false
2025-01-06 23:31:04 - zookeeper.digest.enabled = true
2025-01-06 23:31:04 - zookeeper.closeSessionTxn.enabled = true
2025-01-06 23:31:04 - zookeeper.flushDelay = 0 ms
2025-01-06 23:31:04 - zookeeper.maxWriteQueuePollTime = 0 ms
2025-01-06 23:31:04 - zookeeper.maxBatchSize=1000
2025-01-06 23:31:04 - zookeeper.intBufferStartingSizeBytes = 1024
2025-01-06 23:31:04 - zookeeper.snapshot.trust.empty : false
2025-01-06 23:31:04 - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-06 23:31:04 - Using org.apache.zookeeper.server.watch.WatchManager as watch manager
2025-01-06 23:31:04 - zookeeper.snapshotSizeFactor = 0.33
2025-01-06 23:31:04 - zookeeper.commitLogCount=500
2025-01-06 23:31:04 - Weighed connection throttling is disabled
2025-01-06 23:31:04 - minSessionTimeout set to 1600 ms
2025-01-06 23:31:04 - maxSessionTimeout set to 16000 ms
2025-01-06 23:31:04 - getData response cache size is initialized with value 400.
2025-01-06 23:31:04 - getChildren response cache size is initialized with value 400.
2025-01-06 23:31:04 - zookeeper.pathStats.slotCapacity = 60
2025-01-06 23:31:04 - zookeeper.pathStats.slotDuration = 15
2025-01-06 23:31:04 - zookeeper.pathStats.maxDepth = 6
2025-01-06 23:31:04 - zookeeper.pathStats.initialDelay = 5
2025-01-06 23:31:04 - zookeeper.pathStats.delay = 5
2025-01-06 23:31:04 - zookeeper.pathStats.enabled = false
2025-01-06 23:31:04 - The max bytes for all large requests are set to 104857600
2025-01-06 23:31:04 - The large request threshold is set to -1
2025-01-06 23:31:04 - zookeeper.enforce.auth.enabled = false
2025-01-06 23:31:04 - zookeeper.enforce.auth.schemes = []
2025-01-06 23:31:04 - Created server with tickTime 800 ms minSessionTimeout 1600 ms maxSessionTimeout 16000 ms clientPortListenBacklog -1 datadir C:\Users\hugom\AppData\Local\Temp\kafka-2113216441899699021\version-2 snapdir C:\Users\hugom\AppData\Local\Temp\kafka-17709549323599074218\version-2
2025-01-06 23:31:04 - maxCnxns is not configured, using default value 0.
2025-01-06 23:31:04 - Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers.
2025-01-06 23:31:04 - binding to port /127.0.0.1:0
2025-01-06 23:31:05 - zookeeper.snapshot.compression.method = CHECKED
2025-01-06 23:31:05 - Snapshotting: 0x0 to C:\Users\hugom\AppData\Local\Temp\kafka-17709549323599074218\version-2\snapshot.0
2025-01-06 23:31:05 - Snapshot loaded in 83 ms, highest zxid is 0x0, digest is 1371985504
2025-01-06 23:31:05 - Snapshotting: 0x0 to C:\Users\hugom\AppData\Local\Temp\kafka-17709549323599074218\version-2\snapshot.0
2025-01-06 23:31:05 - Snapshot taken in 2 ms
2025-01-06 23:31:05 - PrepRequestProcessor (sid:0) started, reconfigEnabled=false
2025-01-06 23:31:05 - zookeeper.request_throttler.shutdownTimeout = 10000 ms
2025-01-06 23:31:05 - KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:56039
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-06 23:31:05 - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2025-01-06 23:31:05 - RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false

2025-01-06 23:31:05 - starting
2025-01-06 23:31:05 - Connecting to zookeeper on 127.0.0.1:56039
2025-01-06 23:31:05 - [ZooKeeperClient Kafka server] Initializing a new session to 127.0.0.1:56039.
2025-01-06 23:31:05 - Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC
2025-01-06 23:31:05 - Client environment:host.name=HugoAbreu.home
2025-01-06 23:31:05 - Client environment:java.version=23.0.1
2025-01-06 23:31:05 - Client environment:java.vendor=Oracle Corporation
2025-01-06 23:31:05 - Client environment:java.home=C:\Oracle_JDK-23
2025-01-06 23:31:05 - Client environment:java.class.path=C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator\target\test-classes;C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator\target\classes;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter\3.4.1\spring-boot-starter-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot\3.4.1\spring-boot-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-autoconfigure\3.4.1\spring-boot-autoconfigure-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-logging\3.4.1\spring-boot-starter-logging-3.4.1.jar;C:\Users\hugom\.m2\repository\ch\qos\logback\logback-classic\1.5.12\logback-classic-1.5.12.jar;C:\Users\hugom\.m2\repository\org\apache\logging\log4j\log4j-to-slf4j\2.24.3\log4j-to-slf4j-2.24.3.jar;C:\Users\hugom\.m2\repository\org\apache\logging\log4j\log4j-api\2.24.3\log4j-api-2.24.3.jar;C:\Users\hugom\.m2\repository\org\slf4j\jul-to-slf4j\2.0.16\jul-to-slf4j-2.0.16.jar;C:\Users\hugom\.m2\repository\jakarta\annotation\jakarta.annotation-api\2.1.1\jakarta.annotation-api-2.1.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-core\6.2.1\spring-core-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-jcl\6.2.1\spring-jcl-6.2.1.jar;C:\Users\hugom\.m2\repository\org\yaml\snakeyaml\2.3\snakeyaml-2.3.jar;C:\Users\hugom\.m2\repository\org\springframework\kafka\spring-kafka\3.3.1\spring-kafka-3.3.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-context\6.2.1\spring-context-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-aop\6.2.1\spring-aop-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-beans\6.2.1\spring-beans-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-expression\6.2.1\spring-expression-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-messaging\6.2.1\spring-messaging-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-tx\6.2.1\spring-tx-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\retry\spring-retry\2.0.11\spring-retry-2.0.11.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-clients\3.8.1\kafka-clients-3.8.1.jar;C:\Users\hugom\.m2\repository\com\github\luben\zstd-jni\1.5.6-4\zstd-jni-1.5.6-4.jar;C:\Users\hugom\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\hugom\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.5\snappy-java-1.1.10.5.jar;C:\Users\hugom\.m2\repository\io\micrometer\micrometer-observation\1.14.2\micrometer-observation-1.14.2.jar;C:\Users\hugom\.m2\repository\io\micrometer\micrometer-commons\1.14.2\micrometer-commons-1.14.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-web\3.4.1\spring-boot-starter-web-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-json\3.4.1\spring-boot-starter-json-3.4.1.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jdk8\2.18.2\jackson-datatype-jdk8-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\datatype\jackson-datatype-jsr310\2.18.2\jackson-datatype-jsr310-2.18.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-tomcat\3.4.1\spring-boot-starter-tomcat-3.4.1.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-core\10.1.34\tomcat-embed-core-10.1.34.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-el\10.1.34\tomcat-embed-el-10.1.34.jar;C:\Users\hugom\.m2\repository\org\apache\tomcat\embed\tomcat-embed-websocket\10.1.34\tomcat-embed-websocket-10.1.34.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-web\6.2.1\spring-web-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-webmvc\6.2.1\spring-webmvc-6.2.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-docker-compose\3.4.1\spring-boot-docker-compose-3.4.1.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.18.2\jackson-databind-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.18.2\jackson-annotations-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.18.2\jackson-core-2.18.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\module\jackson-module-parameter-names\2.18.2\jackson-module-parameter-names-2.18.2.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-starter-test\3.4.1\spring-boot-starter-test-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-test\3.4.1\spring-boot-test-3.4.1.jar;C:\Users\hugom\.m2\repository\org\springframework\boot\spring-boot-test-autoconfigure\3.4.1\spring-boot-test-autoconfigure-3.4.1.jar;C:\Users\hugom\.m2\repository\com\jayway\jsonpath\json-path\2.9.0\json-path-2.9.0.jar;C:\Users\hugom\.m2\repository\jakarta\xml\bind\jakarta.xml.bind-api\4.0.2\jakarta.xml.bind-api-4.0.2.jar;C:\Users\hugom\.m2\repository\jakarta\activation\jakarta.activation-api\2.1.3\jakarta.activation-api-2.1.3.jar;C:\Users\hugom\.m2\repository\net\minidev\json-smart\2.5.1\json-smart-2.5.1.jar;C:\Users\hugom\.m2\repository\net\minidev\accessors-smart\2.5.1\accessors-smart-2.5.1.jar;C:\Users\hugom\.m2\repository\org\ow2\asm\asm\9.6\asm-9.6.jar;C:\Users\hugom\.m2\repository\org\assertj\assertj-core\3.26.3\assertj-core-3.26.3.jar;C:\Users\hugom\.m2\repository\net\bytebuddy\byte-buddy\1.15.11\byte-buddy-1.15.11.jar;C:\Users\hugom\.m2\repository\org\awaitility\awaitility\4.2.2\awaitility-4.2.2.jar;C:\Users\hugom\.m2\repository\org\hamcrest\hamcrest\2.2\hamcrest-2.2.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter\5.11.4\junit-jupiter-5.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-params\5.11.4\junit-jupiter-params-5.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-engine\5.11.4\junit-jupiter-engine-5.11.4.jar;C:\Users\hugom\.m2\repository\org\mockito\mockito-core\5.14.2\mockito-core-5.14.2.jar;C:\Users\hugom\.m2\repository\net\bytebuddy\byte-buddy-agent\1.15.11\byte-buddy-agent-1.15.11.jar;C:\Users\hugom\.m2\repository\org\objenesis\objenesis\3.3\objenesis-3.3.jar;C:\Users\hugom\.m2\repository\org\mockito\mockito-junit-jupiter\5.14.2\mockito-junit-jupiter-5.14.2.jar;C:\Users\hugom\.m2\repository\org\skyscreamer\jsonassert\1.5.3\jsonassert-1.5.3.jar;C:\Users\hugom\.m2\repository\com\vaadin\external\google\android-json\0.0.20131108.vaadin1\android-json-0.0.20131108.vaadin1.jar;C:\Users\hugom\.m2\repository\org\springframework\spring-test\6.2.1\spring-test-6.2.1.jar;C:\Users\hugom\.m2\repository\org\xmlunit\xmlunit-core\2.10.0\xmlunit-core-2.10.0.jar;C:\Users\hugom\.m2\repository\org\springframework\kafka\spring-kafka-test\3.3.1\spring-kafka-test-3.3.1.jar;C:\Users\hugom\.m2\repository\org\apache\zookeeper\zookeeper\3.8.4\zookeeper-3.8.4.jar;C:\Users\hugom\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.8.4\zookeeper-jute-3.8.4.jar;C:\Users\hugom\.m2\repository\org\apache\yetus\audience-annotations\0.12.0\audience-annotations-0.12.0.jar;C:\Users\hugom\.m2\repository\io\netty\netty-handler\4.1.116.Final\netty-handler-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-common\4.1.116.Final\netty-common-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-resolver\4.1.116.Final\netty-resolver-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-buffer\4.1.116.Final\netty-buffer-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport\4.1.116.Final\netty-transport-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.116.Final\netty-transport-native-unix-common-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-codec\4.1.116.Final\netty-codec-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-native-epoll\4.1.116.Final\netty-transport-native-epoll-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.116.Final\netty-transport-classes-epoll-4.1.116.Final.jar;C:\Users\hugom\.m2\repository\ch\qos\logback\logback-core\1.5.12\logback-core-1.5.12.jar;C:\Users\hugom\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-clients\3.8.1\kafka-clients-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server\3.8.1\kafka-server-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-group-coordinator\3.8.1\kafka-group-coordinator-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-transaction-coordinator\3.8.1\kafka-transaction-coordinator-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-raft\3.8.1\kafka-raft-3.8.1.jar;C:\Users\hugom\.m2\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-metadata\3.8.1\kafka-metadata-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server-common\3.8.1\kafka-server-common-3.8.1.jar;C:\Users\hugom\.m2\repository\net\sf\jopt-simple\jopt-simple\5.0.4\jopt-simple-5.0.4.jar;C:\Users\hugom\.m2\repository\org\pcollections\pcollections\4.0.1\pcollections-4.0.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-server-common\3.8.1\kafka-server-common-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-streams-test-utils\3.8.1\kafka-streams-test-utils-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-streams\3.8.1\kafka-streams-3.8.1.jar;C:\Users\hugom\.m2\repository\org\rocksdb\rocksdbjni\7.9.2\rocksdbjni-7.9.2.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka_2.13\3.8.1\kafka_2.13-3.8.1.jar;C:\Users\hugom\.m2\repository\org\scala-lang\scala-library\2.13.14\scala-library-2.13.14.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-group-coordinator-api\3.8.1\kafka-group-coordinator-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-storage-api\3.8.1\kafka-storage-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-tools-api\3.8.1\kafka-tools-api-3.8.1.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka-storage\3.8.1\kafka-storage-3.8.1.jar;C:\Users\hugom\.m2\repository\com\github\ben-manes\caffeine\caffeine\3.1.8\caffeine-3.1.8.jar;C:\Users\hugom\.m2\repository\org\checkerframework\checker-qual\3.37.0\checker-qual-3.37.0.jar;C:\Users\hugom\.m2\repository\com\google\errorprone\error_prone_annotations\2.21.1\error_prone_annotations-2.21.1.jar;C:\Users\hugom\.m2\repository\net\sourceforge\argparse4j\argparse4j\0.7.0\argparse4j-0.7.0.jar;C:\Users\hugom\.m2\repository\commons-validator\commons-validator\1.7\commons-validator-1.7.jar;C:\Users\hugom\.m2\repository\commons-beanutils\commons-beanutils\1.9.4\commons-beanutils-1.9.4.jar;C:\Users\hugom\.m2\repository\commons-digester\commons-digester\2.1\commons-digester-2.1.jar;C:\Users\hugom\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.13\2.18.2\jackson-module-scala_2.13-2.18.2.jar;C:\Users\hugom\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\hugom\.m2\repository\com\fasterxml\jackson\dataformat\jackson-dataformat-csv\2.18.2\jackson-dataformat-csv-2.18.2.jar;C:\Users\hugom\.m2\repository\org\bitbucket\b_c\jose4j\0.9.4\jose4j-0.9.4.jar;C:\Users\hugom\.m2\repository\org\scala-lang\modules\scala-collection-compat_2.13\2.10.0\scala-collection-compat_2.13-2.10.0.jar;C:\Users\hugom\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.13\1.0.2\scala-java8-compat_2.13-1.0.2.jar;C:\Users\hugom\.m2\repository\org\scala-lang\scala-reflect\2.13.14\scala-reflect-2.13.14.jar;C:\Users\hugom\.m2\repository\com\typesafe\scala-logging\scala-logging_2.13\3.9.4\scala-logging_2.13-3.9.4.jar;C:\Users\hugom\.m2\repository\io\dropwizard\metrics\metrics-core\4.1.12.1\metrics-core-4.1.12.1.jar;C:\Users\hugom\.m2\repository\commons-cli\commons-cli\1.4\commons-cli-1.4.jar;C:\Users\hugom\.m2\repository\org\apache\kafka\kafka_2.13\3.8.1\kafka_2.13-3.8.1-test.jar;C:\Users\hugom\.m2\repository\org\junit\jupiter\junit-jupiter-api\5.11.4\junit-jupiter-api-5.11.4.jar;C:\Users\hugom\.m2\repository\org\opentest4j\opentest4j\1.3.0\opentest4j-1.3.0.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-commons\1.11.4\junit-platform-commons-1.11.4.jar;C:\Users\hugom\.m2\repository\org\apiguardian\apiguardian-api\1.1.2\apiguardian-api-1.1.2.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-launcher\1.11.4\junit-platform-launcher-1.11.4.jar;C:\Users\hugom\.m2\repository\org\junit\platform\junit-platform-engine\1.11.4\junit-platform-engine-1.11.4.jar;C:\Users\hugom\.m2\repository\org\slf4j\slf4j-api\2.0.16\slf4j-api-2.0.16.jar;
2025-01-06 23:31:05 - Client environment:java.library.path=C:\Oracle_JDK-23\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\nodejs\;C:\Program Files\Git\cmd;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Program Files\Docker\Docker\resources\bin;C:\Users\hugom\Downloads\apache-maven-3.9.9\bin;C:\Users\hugom\AppData\Local\Microsoft\WindowsApps;C:\Users\hugom\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\hugom\AppData\Roaming\npm;C:\Program Files\Git\cmd;C:\Users\hugom\AppData\Local\Android\Sdk\platform-tools;C:\Program Files\sf\bin;;.
2025-01-06 23:31:05 - Client environment:java.io.tmpdir=C:\Users\hugom\AppData\Local\Temp\
2025-01-06 23:31:05 - Client environment:java.compiler=<NA>
2025-01-06 23:31:05 - Client environment:os.name=Windows 11
2025-01-06 23:31:05 - Client environment:os.arch=amd64
2025-01-06 23:31:05 - Client environment:os.version=10.0
2025-01-06 23:31:05 - Client environment:user.name=hugom
2025-01-06 23:31:05 - Client environment:user.home=C:\Users\hugom
2025-01-06 23:31:05 - Client environment:user.dir=C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator
2025-01-06 23:31:05 - Client environment:os.memory.free=54MB
2025-01-06 23:31:05 - Client environment:os.memory.max=3934MB
2025-01-06 23:31:05 - Client environment:os.memory.total=74MB
2025-01-06 23:31:05 - Initiating client connection, connectString=127.0.0.1:56039 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@34074149
2025-01-06 23:31:05 - jute.maxbuffer value is 4194304 Bytes
2025-01-06 23:31:05 - zookeeper.request.timeout value is 0. feature enabled=false
2025-01-06 23:31:05 - [ZooKeeperClient Kafka server] Waiting until connected.
2025-01-06 23:31:05 - Opening socket connection to server /127.0.0.1:56039.
2025-01-06 23:31:05 - Socket connection established, initiating session, client: /127.0.0.1:56040, server: /127.0.0.1:56039
2025-01-06 23:31:05 - Creating new log file: log.1
2025-01-06 23:31:06 - ZooKeeper audit is disabled.
2025-01-06 23:31:06 - Session establishment complete on server /127.0.0.1:56039, session id = 0x100011e7c2d0000, negotiated timeout = 16000
2025-01-06 23:31:06 - [ZooKeeperClient Kafka server] Connected.
2025-01-06 23:31:06 - Cluster ID = ujs8KRg6TmuFeQ83ExzDpA
2025-01-06 23:31:06 - RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false

2025-01-06 23:31:06 - RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false

2025-01-06 23:31:06 - KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 2
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = false
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.8-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617
	log.dir.failure.timeout.ms = 30000
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 2
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = true
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 127.0.0.1:56039
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null

2025-01-06 23:31:06 - RemoteLogManagerConfig values: 
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = 10
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = 10
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false

2025-01-06 23:31:06 - [ThrottledChannelReaper-Fetch]: Starting
2025-01-06 23:31:06 - [ThrottledChannelReaper-Produce]: Starting
2025-01-06 23:31:06 - [ThrottledChannelReaper-Request]: Starting
2025-01-06 23:31:06 - [ThrottledChannelReaper-ControllerMutation]: Starting
2025-01-06 23:31:06 - [KafkaServer id=0] Rewriting C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\meta.properties
2025-01-06 23:31:06 - Loading logs from log dirs ArrayBuffer(C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617)
2025-01-06 23:31:06 - No logs found to be loaded in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617
2025-01-06 23:31:06 - Loaded 0 logs in 27ms
2025-01-06 23:31:06 - Starting log cleanup with a period of 300000 ms.
2025-01-06 23:31:06 - Starting log flusher with a default period of 9223372036854775807 ms.
2025-01-06 23:31:06 - Starting the log cleaner
2025-01-06 23:31:06 - [kafka-log-cleaner-thread-0]: Starting
2025-01-06 23:31:06 - [feature-zk-node-event-process-thread]: Starting
2025-01-06 23:31:06 - Feature ZK node at path: /feature does not exist
2025-01-06 23:31:06 - [zk-broker-0-to-controller-forwarding-channel-manager]: Starting
2025-01-06 23:31:07 - Updated connection-accept-rate max connection creation rate to 2147483647
2025-01-06 23:31:07 - Awaiting socket connections on localhost:56042.
2025-01-06 23:31:07 - Opened wildcard endpoint localhost:56042
2025-01-06 23:31:07 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT)
2025-01-06 23:31:07 - [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting
2025-01-06 23:31:07 - [ExpirationReaper-0-Produce]: Starting
2025-01-06 23:31:07 - [ExpirationReaper-0-Fetch]: Starting
2025-01-06 23:31:07 - [ExpirationReaper-0-DeleteRecords]: Starting
2025-01-06 23:31:07 - [ExpirationReaper-0-ElectLeader]: Starting
2025-01-06 23:31:07 - [ExpirationReaper-0-RemoteFetch]: Starting
2025-01-06 23:31:07 - [LogDirFailureHandler]: Starting
2025-01-06 23:31:07 - [AddPartitionsToTxnSenderThread-0]: Starting
2025-01-06 23:31:07 - Creating /brokers/ids/0 (is it secure? false)
2025-01-06 23:31:07 - Stat of the created znode at /brokers/ids/0 is: 25,25,1736206267955,1736206267955,1,0,0,72058824481898496,204,0,25

2025-01-06 23:31:07 - Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://localhost:56042, czxid (broker epoch): 25
2025-01-06 23:31:08 - [ControllerEventThread controllerId=0] Starting
2025-01-06 23:31:08 - [ExpirationReaper-0-topic]: Starting
2025-01-06 23:31:08 - [ExpirationReaper-0-Heartbeat]: Starting
2025-01-06 23:31:08 - [ExpirationReaper-0-Rebalance]: Starting
2025-01-06 23:31:08 - Successfully created /controller_epoch with initial epoch 0
2025-01-06 23:31:08 - [Controller id=0] 0 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1
2025-01-06 23:31:08 - [Controller id=0] Creating FeatureZNode at path: /feature with contents: FeatureZNode(2,Enabled,Map())
2025-01-06 23:31:08 - Feature ZK node created at path: /feature
2025-01-06 23:31:08 - [GroupCoordinator 0]: Starting up.
2025-01-06 23:31:08 - [GroupCoordinator 0]: Startup complete.
2025-01-06 23:31:08 - [TransactionCoordinator id=0] Starting up.
2025-01-06 23:31:08 - [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.8-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0).
2025-01-06 23:31:08 - [Controller id=0] Registering handlers
2025-01-06 23:31:08 - [TxnMarkerSenderThread-0]: Starting
2025-01-06 23:31:08 - [TransactionCoordinator id=0] Startup complete.
2025-01-06 23:31:08 - [Controller id=0] Deleting log dir event notifications
2025-01-06 23:31:08 - [Controller id=0] Deleting isr change notifications
2025-01-06 23:31:08 - [Controller id=0] Initializing controller context
2025-01-06 23:31:08 - [Controller id=0] Initialized broker epochs cache: HashMap(0 -> 25)
2025-01-06 23:31:08 - [RequestSendThread controllerId=0] Starting
2025-01-06 23:31:08 - [Controller id=0] Currently active brokers in the cluster: Set(0)
2025-01-06 23:31:08 - [Controller id=0] Currently shutting brokers in the cluster: HashSet()
2025-01-06 23:31:08 - [Controller id=0] Current list of topics in the cluster: HashSet()
2025-01-06 23:31:08 - [Controller id=0] Fetching topic deletions in progress
2025-01-06 23:31:08 - [Controller id=0] List of topics to be deleted: 
2025-01-06 23:31:08 - [Controller id=0] List of topics ineligible for deletion: 
2025-01-06 23:31:08 - [Controller id=0] Initializing topic deletion manager
2025-01-06 23:31:08 - [Topic Deletion Manager 0] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet()
2025-01-06 23:31:08 - [Controller id=0] Sending update metadata request
2025-01-06 23:31:08 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 0 partitions
2025-01-06 23:31:08 - [ReplicaStateMachine controllerId=0] Initializing replica state
2025-01-06 23:31:08 - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
2025-01-06 23:31:08 - [ReplicaStateMachine controllerId=0] Triggering offline replica state changes
2025-01-06 23:31:08 - [PartitionStateMachine controllerId=0] Initializing partition state
2025-01-06 23:31:08 - [PartitionStateMachine controllerId=0] Triggering online partition state changes
2025-01-06 23:31:08 - [RequestSendThread controllerId=0] Controller 0 connected to localhost:56042 (id: 0 rack: null) for sending state change requests
2025-01-06 23:31:08 - [Controller id=0] Ready to serve as the new controller with epoch 1
2025-01-06 23:31:08 - [ExpirationReaper-0-AlterAcls]: Starting
2025-01-06 23:31:08 - [Controller id=0] Partitions undergoing preferred replica election: 
2025-01-06 23:31:08 - [Controller id=0] Partitions that completed preferred replica election: 
2025-01-06 23:31:08 - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
2025-01-06 23:31:08 - [Controller id=0] Resuming preferred replica election for partitions: 
2025-01-06 23:31:08 - [Controller id=0] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered
2025-01-06 23:31:08 - [Controller id=0] Starting the controller scheduler
2025-01-06 23:31:08 - [/config/changes-event-process-thread]: Starting
2025-01-06 23:31:08 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing.
2025-01-06 23:31:08 - [KafkaServer id=0] Start processing authorizer futures
2025-01-06 23:31:08 - [KafkaServer id=0] End processing authorizer futures
2025-01-06 23:31:08 - [KafkaServer id=0] Start processing enable request processing future
2025-01-06 23:31:08 - [KafkaServer id=0] End processing enable request processing future
2025-01-06 23:31:08 - Kafka version: 3.8.1
2025-01-06 23:31:08 - Kafka commitId: 70d6ff42debf7e17
2025-01-06 23:31:08 - Kafka startTimeMs: 1736206268565
2025-01-06 23:31:08 - [KafkaServer id=0] started
2025-01-06 23:31:08 - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [127.0.0.1:56042]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-01-06 23:31:08 - [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node localhost:56042 (id: 0 rack: null)
2025-01-06 23:31:08 - [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node localhost:56042 (id: 0 rack: null)
2025-01-06 23:31:08 - Kafka version: 3.8.1
2025-01-06 23:31:08 - Kafka commitId: 70d6ff42debf7e17
2025-01-06 23:31:08 - Kafka startTimeMs: 1736206268705
2025-01-06 23:31:08 - Creating topic calculation-results with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-01-06 23:31:08 - [Controller id=0] New topics: [Set(calculation-results)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(calculation-results,Some(AcbUf-hzSQ26iRFfo0zjgA),Map(calculation-results-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-06 23:31:08 - [Controller id=0] New partition creation callback for calculation-results-0
2025-01-06 23:31:08 - [Controller id=0 epoch=1] Changed partition calculation-results-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:08 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:08 - Creating topic calculation-requests with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0))
2025-01-06 23:31:08 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Changed partition calculation-results-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:09 - [Controller id=0] New topics: [Set(calculation-requests)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(calculation-requests,Some(m_54phrSRXWsFzWctwUjgg),Map(calculation-requests-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-06 23:31:09 - [Controller id=0] New partition creation callback for calculation-requests-0
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Changed partition calculation-requests-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:09 - [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 for 1 partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Changed partition calculation-requests-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 1 become-leader and 0 become-follower partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 1 partitions
2025-01-06 23:31:09 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:09 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(calculation-results-0)
2025-01-06 23:31:09 - [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-01-06 23:31:09 - [LogLoader partition=calculation-results-0, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:09 - Created log for partition calculation-results-0 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\calculation-results-0 with properties {}
2025-01-06 23:31:09 - [Partition calculation-results-0 broker=0] No checkpointed highwatermark is found for partition calculation-results-0
2025-01-06 23:31:09 - [Partition calculation-results-0 broker=0] Log loaded for partition calculation-results-0 with initial high watermark 0
2025-01-06 23:31:09 - [Broker id=0] Leader calculation-results-0 with topic id Some(AcbUf-hzSQ26iRFfo0zjgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:09 - [Broker id=0] Finished LeaderAndIsr request in 316ms correlationId 1 from controller 0 for 1 partitions
2025-01-06 23:31:09 - [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2
2025-01-06 23:31:09 - [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 for 1 partitions
2025-01-06 23:31:09 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(calculation-requests-0)
2025-01-06 23:31:09 - [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 3 from controller 0 epoch 1 as part of the become-leader transition for 1 partitions
2025-01-06 23:31:09 - [LogLoader partition=calculation-requests-0, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:09 - Created log for partition calculation-requests-0 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\calculation-requests-0 with properties {}
2025-01-06 23:31:09 - [Partition calculation-requests-0 broker=0] No checkpointed highwatermark is found for partition calculation-requests-0
2025-01-06 23:31:09 - [Partition calculation-requests-0 broker=0] Log loaded for partition calculation-requests-0 with initial high watermark 0
2025-01-06 23:31:09 - [Broker id=0] Leader calculation-requests-0 with topic id Some(m_54phrSRXWsFzWctwUjgg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:09 - [Broker id=0] Finished LeaderAndIsr request in 46ms correlationId 3 from controller 0 for 1 partitions
2025-01-06 23:31:09 - [Broker id=0] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4
2025-01-06 23:31:09 - App info kafka.admin.client for adminclient-1 unregistered
2025-01-06 23:31:09 - Metrics scheduler closed
2025-01-06 23:31:09 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-06 23:31:09 - Metrics reporters closed
2025-01-06 23:31:09 - Starting CalculatorServiceTest using Java 23.0.1 with PID 24296 (started by hugom in C:\Users\hugom\OneDrive\Ambiente de Trabalho\CalculatorRestAPI\calculator)
2025-01-06 23:31:09 - No active profile set, falling back to 1 default profile: "default"
2025-01-06 23:31:13 - [Controller id=0] Processing automatic preferred replica leader election
2025-01-06 23:31:13 - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:56042]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-calculator-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = calculator-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2025-01-06 23:31:13 - initializing Kafka metrics collector
2025-01-06 23:31:13 - Kafka version: 3.8.1
2025-01-06 23:31:13 - Kafka commitId: 70d6ff42debf7e17
2025-01-06 23:31:13 - Kafka startTimeMs: 1736206273808
2025-01-06 23:31:13 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Subscribed to topic(s): calculation-requests
2025-01-06 23:31:13 - Started CalculatorServiceTest in 10.853 seconds (process running for 14.521)
2025-01-06 23:31:13 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Cluster ID: ujs8KRg6TmuFeQ83ExzDpA
2025-01-06 23:31:13 - Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0))
2025-01-06 23:31:13 - [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [Set(TopicIdReplicaAssignment(__consumer_offsets,Some(eDFVnOaZR2iqp2wV-rZQgA),HashMap(__consumer_offsets-4 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=0, addingReplicas=, removingReplicas=))))]
2025-01-06 23:31:13 - [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 state from NonExistentPartition to NewPartition with assigned replicas 0
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-4 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-3 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Changed partition __consumer_offsets-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isrWithBrokerEpoch=List(BrokerState(brokerId=0, brokerEpoch=-1)), leaderRecoveryState=RECOVERED, partitionEpoch=0)
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Sending LeaderAndIsr request to broker 0 with 5 become-leader and 0 become-follower partitions
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet(0) for 5 partitions
2025-01-06 23:31:13 - [Controller id=0 epoch=1] Sending UpdateMetadata request to brokers HashSet() for 0 partitions
2025-01-06 23:31:13 - [Broker id=0] Handling LeaderAndIsr request correlationId 5 from controller 0 for 5 partitions
2025-01-06 23:31:13 - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-4, __consumer_offsets-3, __consumer_offsets-2, __consumer_offsets-0, __consumer_offsets-1)
2025-01-06 23:31:13 - [Broker id=0] Stopped fetchers as part of LeaderAndIsr request correlationId 5 from controller 0 epoch 1 as part of the become-leader transition for 5 partitions
2025-01-06 23:31:14 - [LogLoader partition=__consumer_offsets-3, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:14 - Created log for partition __consumer_offsets-3 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-06 23:31:14 - [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2025-01-06 23:31:14 - [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0
2025-01-06 23:31:14 - [Broker id=0] Leader __consumer_offsets-3 with topic id Some(eDFVnOaZR2iqp2wV-rZQgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:14 - [LogLoader partition=__consumer_offsets-2, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:14 - Created log for partition __consumer_offsets-2 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-06 23:31:14 - [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2025-01-06 23:31:14 - [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0
2025-01-06 23:31:14 - [Broker id=0] Leader __consumer_offsets-2 with topic id Some(eDFVnOaZR2iqp2wV-rZQgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:14 - [LogLoader partition=__consumer_offsets-4, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:14 - Created log for partition __consumer_offsets-4 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-06 23:31:14 - [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2025-01-06 23:31:14 - [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0
2025-01-06 23:31:14 - [Broker id=0] Leader __consumer_offsets-4 with topic id Some(eDFVnOaZR2iqp2wV-rZQgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:14 - [LogLoader partition=__consumer_offsets-1, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:14 - Created log for partition __consumer_offsets-1 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-06 23:31:14 - [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2025-01-06 23:31:14 - [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0
2025-01-06 23:31:14 - [Broker id=0] Leader __consumer_offsets-1 with topic id Some(eDFVnOaZR2iqp2wV-rZQgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:14 - [LogLoader partition=__consumer_offsets-0, dir=C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617] Loading producer state till offset 0 with message format version 2
2025-01-06 23:31:14 - Created log for partition __consumer_offsets-0 in C:\Users\hugom\AppData\Local\Temp\spring.kafka.524d4eae-fc7f-4797-835f-ff70351a18a312062415252289157617\__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600}
2025-01-06 23:31:14 - [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2025-01-06 23:31:14 - [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0
2025-01-06 23:31:14 - [Broker id=0] Leader __consumer_offsets-0 with topic id Some(eDFVnOaZR2iqp2wV-rZQgA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [0], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1.
2025-01-06 23:31:14 - [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0
2025-01-06 23:31:14 - [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0
2025-01-06 23:31:14 - [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0
2025-01-06 23:31:14 - [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0
2025-01-06 23:31:14 - [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0
2025-01-06 23:31:14 - [Broker id=0] Finished LeaderAndIsr request in 139ms correlationId 5 from controller 0 for 5 partitions
2025-01-06 23:31:14 - [Broker id=0] Add 5 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 6
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler.
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler.
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 16 milliseconds for epoch 0, of which 16 milliseconds was spent in the scheduler.
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 17 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler.
2025-01-06 23:31:14 - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 18 milliseconds for epoch 0, of which 17 milliseconds was spent in the scheduler.
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Discovered group coordinator localhost:56042 (id: 2147483647 rack: null)
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] (Re-)joining group
2025-01-06 23:31:14 - [GroupCoordinator 0]: Dynamic member with unknown member id joins group calculator-group in Empty state. Created a new member id consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde and request the member to rejoin with this id.
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Request joining group due to: need to re-join with the given member-id: consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] (Re-)joining group
2025-01-06 23:31:14 - [GroupCoordinator 0]: Preparing to rebalance group calculator-group in state PreparingRebalance with old generation 0 (__consumer_offsets-1) (reason: Adding new member consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde with group instance id None; client reason: need to re-join with the given member-id: consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde)
2025-01-06 23:31:14 - [GroupCoordinator 0]: Stabilized group calculator-group generation 1 (__consumer_offsets-1) with 1 members
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde', protocol='range'}
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Finished assignment for group at generation 1: {consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde=Assignment(partitions=[calculation-requests-0])}
2025-01-06 23:31:14 - [GroupCoordinator 0]: Assignment received from leader consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde for group calculator-group for generation 1. The group has 1 members, 0 of which are static.
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde', protocol='range'}
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Notifying assignor about the new Assignment(partitions=[calculation-requests-0])
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Adding newly assigned partitions: calculation-requests-0
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Found no committed offset for partition calculation-requests-0
2025-01-06 23:31:14 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Resetting offset for partition calculation-requests-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:56042 (id: 0 rack: null)], epoch=0}}.
2025-01-06 23:31:14 - calculator-group: partitions assigned: [calculation-requests-0]
2025-01-06 23:31:16 - Received calculation request: 12350,invalid,10,5
2025-01-06 23:31:16 - Invalid operation for requestId: 12350
2025-01-06 23:31:16 - Received calculation request: 12346,subtract,10,5
2025-01-06 23:31:17 - Sent result for requestId 12346: 5
2025-01-06 23:31:17 - Received calculation request: 12348,divide,10.6,5
2025-01-06 23:31:17 - Sent result for requestId 12348: 2.1
2025-01-06 23:31:17 - Received calculation request: 123530,sum,10
2025-01-06 23:31:17 - Error processing Kafka message: 123530,sum,10
java.lang.IllegalArgumentException: Invalid message format: 123530,sum,10
	at com.example.CalculatorService.processRequest(CalculatorService.java:44)
	at com.example.CalculatorServiceTest.testProcessRequest_three_parts(CalculatorServiceTest.java:164)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:767)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$8(TestMethodTestDescriptor.java:217)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:156)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1597)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:160)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:146)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:144)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:56)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:184)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:148)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:122)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
2025-01-06 23:31:17 - Received calculation request: 12347,multiply,10,5
2025-01-06 23:31:17 - Sent result for requestId 12347: 50
2025-01-06 23:31:17 - Received calculation request: 12345,sum,10,5
2025-01-06 23:31:17 - Sent result for requestId 12345: 15
2025-01-06 23:31:17 - Error deleting C:\Users\hugom\AppData\Local\Temp\kafka-2113216441899699021
java.nio.file.FileSystemException: C:\Users\hugom\AppData\Local\Temp\kafka-2113216441899699021\version-2\log.1: O processo no pode aceder ao ficheiro porque este est a ser utilizado por outro processo
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:273)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105)
	at java.base/java.nio.file.Files.delete(Files.java:1153)
	at org.apache.kafka.common.utils.Utils$1.visitFile(Utils.java:879)
	at org.apache.kafka.common.utils.Utils$1.visitFile(Utils.java:868)
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2810)
	at java.base/java.nio.file.Files.walkFileTree(Files.java:2881)
	at org.apache.kafka.common.utils.Utils.delete(Utils.java:868)
	at org.apache.kafka.test.TestUtils.lambda$tempDirectory$0(TestUtils.java:274)
	at java.base/java.lang.Thread.run(Thread.java:1575)
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Revoke previously assigned partitions calculation-requests-0
2025-01-06 23:31:17 - calculator-group: partitions revoked: [calculation-requests-0]
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Member consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde sending LeaveGroup request to coordinator localhost:56042 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Unsubscribed all topics or patterns and assigned partitions
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-01-06 23:31:17 - [Consumer clientId=consumer-calculator-group-1, groupId=calculator-group] Request joining group due to: consumer pro-actively leaving the group
2025-01-06 23:31:17 - [GroupCoordinator 0]: Preparing to rebalance group calculator-group in state PreparingRebalance with old generation 1 (__consumer_offsets-1) (reason: Removing member consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde on LeaveGroup; client reason: the consumer unsubscribed from all topics)
2025-01-06 23:31:17 - [GroupCoordinator 0]: Group calculator-group with generation 2 is now empty (__consumer_offsets-1)
2025-01-06 23:31:17 - [GroupCoordinator 0]: Member MemberMetadata(memberId=consumer-calculator-group-1-cbb5e496-18ae-4ff9-9aee-a25243851cde, groupInstanceId=None, clientId=consumer-calculator-group-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group calculator-group through explicit `LeaveGroup`; client reason: the consumer unsubscribed from all topics
2025-01-06 23:31:17 - Metrics scheduler closed
2025-01-06 23:31:17 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-06 23:31:17 - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-01-06 23:31:17 - Metrics reporters closed
2025-01-06 23:31:17 - App info kafka.consumer for consumer-calculator-group-1 unregistered
2025-01-06 23:31:17 - calculator-group: Consumer stopped
2025-01-06 23:31:17 - [KafkaServer id=0] shutting down
2025-01-06 23:31:17 - [/config/changes-event-process-thread]: Shutting down
2025-01-06 23:31:17 - [/config/changes-event-process-thread]: Shutdown completed
2025-01-06 23:31:17 - [/config/changes-event-process-thread]: Stopped
2025-01-06 23:31:17 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors
2025-01-06 23:31:17 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors
2025-01-06 23:31:17 - [data-plane Kafka Request Handler on Broker 0], shutting down
2025-01-06 23:31:17 - [data-plane Kafka Request Handler on Broker 0], shut down completely
2025-01-06 23:31:17 - [ExpirationReaper-0-AlterAcls]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-AlterAcls]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-AlterAcls]: Stopped
2025-01-06 23:31:17 - [KafkaApi-0] Shutdown complete.
2025-01-06 23:31:17 - [ExpirationReaper-0-topic]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-topic]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-topic]: Shutdown completed
2025-01-06 23:31:17 - [TransactionCoordinator id=0] Shutting down.
2025-01-06 23:31:17 - [Transaction State Manager 0]: Shutdown complete
2025-01-06 23:31:17 - [TxnMarkerSenderThread-0]: Shutting down
2025-01-06 23:31:17 - [TxnMarkerSenderThread-0]: Stopped
2025-01-06 23:31:17 - [TxnMarkerSenderThread-0]: Shutdown completed
2025-01-06 23:31:17 - [TransactionCoordinator id=0] Shutdown complete.
2025-01-06 23:31:17 - [GroupCoordinator 0]: Shutting down.
2025-01-06 23:31:17 - [ExpirationReaper-0-Heartbeat]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-Heartbeat]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-Heartbeat]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-Rebalance]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-Rebalance]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-Rebalance]: Shutdown completed
2025-01-06 23:31:17 - [GroupCoordinator 0]: Shutdown complete.
2025-01-06 23:31:17 - [ReplicaManager broker=0] Shutting down
2025-01-06 23:31:17 - [LogDirFailureHandler]: Shutting down
2025-01-06 23:31:17 - [LogDirFailureHandler]: Stopped
2025-01-06 23:31:17 - [LogDirFailureHandler]: Shutdown completed
2025-01-06 23:31:17 - [ReplicaFetcherManager on broker 0] shutting down
2025-01-06 23:31:17 - [ReplicaFetcherManager on broker 0] shutdown completed
2025-01-06 23:31:17 - [ReplicaAlterLogDirsManager on broker 0] shutting down
2025-01-06 23:31:17 - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-Fetch]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-Fetch]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-Fetch]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-RemoteFetch]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-RemoteFetch]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-RemoteFetch]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-Produce]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-Produce]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-Produce]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-DeleteRecords]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2025-01-06 23:31:17 - [ExpirationReaper-0-DeleteRecords]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-ElectLeader]: Shutting down
2025-01-06 23:31:17 - [ExpirationReaper-0-ElectLeader]: Stopped
2025-01-06 23:31:17 - [ExpirationReaper-0-ElectLeader]: Shutdown completed
2025-01-06 23:31:17 - [AddPartitionsToTxnSenderThread-0]: Shutting down
2025-01-06 23:31:17 - [AddPartitionsToTxnSenderThread-0]: Stopped
2025-01-06 23:31:17 - [AddPartitionsToTxnSenderThread-0]: Shutdown completed
2025-01-06 23:31:17 - [ReplicaManager broker=0] Shut down completely
2025-01-06 23:31:17 - [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down
2025-01-06 23:31:17 - [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed
2025-01-06 23:31:17 - [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped
2025-01-06 23:31:17 - Node to controller channel manager for alter-partition shutdown
2025-01-06 23:31:17 - [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down
2025-01-06 23:31:17 - [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped
2025-01-06 23:31:17 - [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed
2025-01-06 23:31:17 - Node to controller channel manager for forwarding shutdown
2025-01-06 23:31:17 - Shutting down.
2025-01-06 23:31:17 - Shutting down the log cleaner.
2025-01-06 23:31:17 - [kafka-log-cleaner-thread-0]: Shutting down
2025-01-06 23:31:17 - [kafka-log-cleaner-thread-0]: Shutdown completed
2025-01-06 23:31:17 - [kafka-log-cleaner-thread-0]: Stopped
2025-01-06 23:31:17 - [ProducerStateManager partition=__consumer_offsets-1] Wrote producer snapshot at offset 2 with 0 producer ids in 4 ms.
2025-01-06 23:31:18 - Shutdown complete.
2025-01-06 23:31:18 - [ControllerEventThread controllerId=0] Shutting down
2025-01-06 23:31:18 - [ControllerEventThread controllerId=0] Stopped
2025-01-06 23:31:18 - [ControllerEventThread controllerId=0] Shutdown completed
2025-01-06 23:31:18 - [PartitionStateMachine controllerId=0] Stopped partition state machine
2025-01-06 23:31:18 - [ReplicaStateMachine controllerId=0] Stopped replica state machine
2025-01-06 23:31:18 - [RequestSendThread controllerId=0] Shutting down
2025-01-06 23:31:18 - [RequestSendThread controllerId=0] Stopped
2025-01-06 23:31:18 - [RequestSendThread controllerId=0] Shutdown completed
2025-01-06 23:31:18 - [Controller id=0] Resigned
2025-01-06 23:31:18 - [feature-zk-node-event-process-thread]: Shutting down
2025-01-06 23:31:18 - [feature-zk-node-event-process-thread]: Stopped
2025-01-06 23:31:18 - [feature-zk-node-event-process-thread]: Shutdown completed
2025-01-06 23:31:18 - [ZooKeeperClient Kafka server] Closing.
2025-01-06 23:31:18 - Session: 0x100011e7c2d0000 closed
2025-01-06 23:31:18 - EventThread shut down for session: 0x100011e7c2d0000
2025-01-06 23:31:18 - [ZooKeeperClient Kafka server] Closed.
2025-01-06 23:31:18 - [ThrottledChannelReaper-Fetch]: Shutting down
2025-01-06 23:31:18 - [ThrottledChannelReaper-Fetch]: Shutdown completed
2025-01-06 23:31:18 - [ThrottledChannelReaper-Fetch]: Stopped
2025-01-06 23:31:18 - [ThrottledChannelReaper-Produce]: Shutting down
2025-01-06 23:31:18 - [ThrottledChannelReaper-Produce]: Stopped
2025-01-06 23:31:18 - [ThrottledChannelReaper-Produce]: Shutdown completed
2025-01-06 23:31:18 - [ThrottledChannelReaper-Request]: Shutting down
2025-01-06 23:31:18 - [ThrottledChannelReaper-Request]: Shutdown completed
2025-01-06 23:31:18 - [ThrottledChannelReaper-Request]: Stopped
2025-01-06 23:31:18 - [ThrottledChannelReaper-ControllerMutation]: Shutting down
2025-01-06 23:31:18 - [ThrottledChannelReaper-ControllerMutation]: Shutdown completed
2025-01-06 23:31:18 - [ThrottledChannelReaper-ControllerMutation]: Stopped
2025-01-06 23:31:18 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server
2025-01-06 23:31:18 - [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed
2025-01-06 23:31:18 - Metrics scheduler closed
2025-01-06 23:31:18 - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-06 23:31:18 - Metrics reporters closed
2025-01-06 23:31:18 - Broker and topic stats closed
2025-01-06 23:31:18 - App info kafka.server for 0 unregistered
2025-01-06 23:31:18 - [KafkaServer id=0] shut down completed
2025-01-06 23:31:18 - ConnnectionExpirerThread interrupted
2025-01-06 23:31:18 - accept thread exitted run method
2025-01-06 23:31:18 - selector thread exitted run method
2025-01-06 23:31:18 - selector thread exitted run method
2025-01-06 23:31:18 - shutting down
2025-01-06 23:31:18 - Shutting down
2025-01-06 23:31:18 - Draining request throttler queue
2025-01-06 23:31:18 - RequestThrottler shutdown. Dropped 0 requests
2025-01-06 23:31:18 - Shutting down
2025-01-06 23:31:18 - Shutting down
2025-01-06 23:31:18 - Shutting down
2025-01-06 23:31:18 - PrepRequestProcessor exited loop!
2025-01-06 23:31:18 - SyncRequestProcessor exited!
2025-01-06 23:31:18 - shutdown of request processor complete
